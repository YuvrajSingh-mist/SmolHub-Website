---
title: "Bert"
excerpt: "Implementation of BERT from the Paper Replications repository"
collection: paper_replications
layout: paper-replication
category: "Language Models"
framework: "PyTorch"
dataset: "Cornell Movie Dialogs"
github_url: "https://github.com/YuvrajSingh-mist/Paper-Replications/tree/master/BERT"
date: 2025-08-07
---

## Overview
Implementation of BERT from the Paper Replications repository

## Key Features
- Transformer Architecture

## Technical Details
- **Framework**: PyTorch
- **Dataset**: Cornell Movie Dialogs
- **Category**: Language Models

## Implementation Details

# BERT architecture in Pytorch

I implemented the BERT using Pytorch on Cornell Movie Dialog Corpus.

[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)

### Datasets

**Cornell Movie Dialog Corpus**: [Link](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html)

### Frameworks:
**Pytorch**

## Source Code
üìÅ **GitHub Repository**: [BERT](https://github.com/YuvrajSingh-mist/Paper-Replications/tree/master/BERT)

View the complete implementation, training scripts, and documentation on GitHub.
