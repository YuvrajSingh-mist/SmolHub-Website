---
title: "Clip"
excerpt: "Implementation of CLiP from the Paper Replications repository"
collection: models
layout: paper-replication
category: "Computer Vision"
framework: "PyTorch"
dataset: "Flickr"
github_url: "https://github.com/YuvrajSingh-mist/Paper-Replications/tree/master/CLiP"
date: 2025-08-07
---

## Overview
Implementation of CLiP from the Paper Replications repository

## Key Features
- Vision-Language

## Technical Details
- **Framework**: PyTorch
- **Dataset**: Flickr
- **Category**: Computer Vision

## Implementation Details

# CLIP architecture in Pytorch

I implemented the CLiP using Pytorch on the flickr8000 dataset.

[Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020)

### Datasets

**flickr 8000**: [Link](https://www.kaggle.com/datasets/adityajn105/flickr8k)

### Frameworks:
**Pytorch**

### Results (on T4 GPU Single)

**Training epochs:** 30

**Train loss:** 1.3
**Val loss:** 2.2

## Source Code
üìÅ **GitHub Repository**: [CLiP](https://github.com/YuvrajSingh-mist/Paper-Replications/tree/master/CLiP)

View the complete implementation, training scripts, and documentation on GitHub.
