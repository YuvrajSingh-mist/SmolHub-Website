---
title: "ViT"
excerpt: "From scratch implementation of ViT"
collection: models
layout: model-implementation
category: "Computer Vision"
framework: "PyTorch"
dataset: "Custom"
github_url: "https://github.com/YuvrajSingh-mist/Paper-Replications/tree/master/ViT"
date: 2024-06-20
---

## Overview
From scratch implementation of ViT

## Key Features
- Transformer Architecture

## Technical Details
- **Framework**: PyTorch
- **Dataset**: Custom
- **Category**: Computer Vision

## Implementation Details

Implmented a ViT Architecture from Scratch using Pytorch on a subset of Food-101 dataset.

[An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/1511.06434)

## Dataset Information

**Dataset (Train):** Subset of Food101 (3 classes-255 images total)
**Dataset (Test):** Subset of Food101 (3 classes-75 images total)

### Frameworks

**Pytorch**

## Results

**Training loss**: 1.20 \
**Test loss**: 1.52
## Authors

- [@YuvrajSingh](https://www.github.com/YuvrajSingh-mist)

## Source Code
üìÅ **GitHub Repository**: [ViT](https://github.com/YuvrajSingh-mist/Paper-Replications/tree/master/ViT)

View the complete implementation, training scripts, and documentation on GitHub.
